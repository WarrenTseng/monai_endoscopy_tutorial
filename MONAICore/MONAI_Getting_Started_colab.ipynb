{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3cb85aa",
      "metadata": {
        "id": "e3cb85aa"
      },
      "source": [
        "### We will introduce:\n",
        "1. **MONAI Getting Started**\n",
        "    - Transformation\n",
        "    - Datset\n",
        "    - Network\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://docs.monai.io/en/stable/_images/end_to_end.png)"
      ],
      "metadata": {
        "id": "_zImpw3ag9PQ"
      },
      "id": "_zImpw3ag9PQ"
    },
    {
      "cell_type": "markdown",
      "id": "3fc7af2f",
      "metadata": {
        "id": "3fc7af2f"
      },
      "source": [
        "### Reference: <a href=\"https://github.com/Project-MONAI/MONAIBootcamp2021\">MONAI bootcamp 2021</a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai nibabel"
      ],
      "metadata": {
        "id": "1WSvNjmWblPI"
      },
      "id": "1WSvNjmWblPI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0d21065",
      "metadata": {
        "id": "b0d21065"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import monai\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eddbf64",
      "metadata": {
        "id": "9eddbf64"
      },
      "source": [
        "## Creating dummy data\n",
        "- monai.data.create_test_image_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ff1a2ae5",
      "metadata": {
        "id": "ff1a2ae5"
      },
      "outputs": [],
      "source": [
        "keys = [\"img\", \"seg\"]\n",
        "filenames = []\n",
        "root_dir = './data'\n",
        "!mkdir $root_dir\n",
        "n_data = 5\n",
        "\n",
        "for i in range(n_data):\n",
        "    im, seg = monai.data.create_test_image_3d(256, 256, 256, num_objs=25, rad_max=50)\n",
        "\n",
        "    im_filename = f\"{root_dir}/im{i}.nii.gz\"\n",
        "    seg_filename = f\"{root_dir}/seg{i}.nii.gz\"\n",
        "    filenames.append({\"img\": im_filename, \"seg\": seg_filename})\n",
        "\n",
        "    n = nib.Nifti1Image(im, np.eye(4))\n",
        "    nib.save(n, im_filename)\n",
        "\n",
        "    n = nib.Nifti1Image(seg, np.eye(4))\n",
        "    nib.save(n, seg_filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls './data'"
      ],
      "metadata": {
        "id": "BKSE9bh3b8d_"
      },
      "id": "BKSE9bh3b8d_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4698edeb",
      "metadata": {
        "id": "4698edeb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(121)\n",
        "plt.imshow(im[128], cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(seg[128], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d26affa",
      "metadata": {
        "id": "3d26affa"
      },
      "outputs": [],
      "source": [
        "im.min(), im.max(), seg.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63ecd636",
      "metadata": {
        "id": "63ecd636"
      },
      "source": [
        "## Transforms\n",
        "https://docs.monai.io/en/latest/transforms.html\n",
        "- monai.transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fad2366",
      "metadata": {
        "id": "3fad2366"
      },
      "source": [
        "\"Medical images require highly specialized methods for **I/O, preprocessing, and augmentation**. Medical images are often in specialized formats with rich meta-information, and the data volumes are often high-dimensional. These require carefully designed manipulation procedures. The medical imaging focus of MONAI is enabled by powerful and flexible image transformations that facilitate user-friendly, reproducible, optimized medical data pre-processing pipelines.\" <a href=\"https://docs.monai.io/en/latest/highlights.html#medical-image-data-i-o-processing-and-augmentation\">Source</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "49b50490",
      "metadata": {
        "id": "49b50490"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImage(image_only=True), # I/O\n",
        "                                  monai.transforms.AddChannel(), # Pre-processing\n",
        "                                  monai.transforms.RandGaussianNoise(prob=0.5, std=0.5), # Augmentation\n",
        "                                  monai.transforms.ToTensor()]) # Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc772991",
      "metadata": {
        "id": "bc772991"
      },
      "outputs": [],
      "source": [
        "filenames[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef5142c",
      "metadata": {
        "id": "8ef5142c"
      },
      "outputs": [],
      "source": [
        "# Run this cell several times to check the rand term\n",
        "img = trans(filenames[0][\"img\"])\n",
        "print(type(img), img.shape)\n",
        "plt.imshow(img[0, 128], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773f1218",
      "metadata": {
        "id": "773f1218"
      },
      "source": [
        "1. Customize transforms: Lambda\n",
        "    - monai.transforms.Lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbc9c1f",
      "metadata": {
        "id": "afbc9c1f"
      },
      "outputs": [],
      "source": [
        "def sum_width(img):\n",
        "    return img.sum(1)\n",
        "\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImage(image_only=True), \n",
        "                                  monai.transforms.AddChannel(), \n",
        "                                  monai.transforms.Lambda(sum_width)])\n",
        "img = trans(filenames[0][\"img\"])\n",
        "plt.imshow(img[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "031bd00c",
      "metadata": {
        "id": "031bd00c"
      },
      "source": [
        "2. Customize transforms: inherit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb85306",
      "metadata": {
        "id": "fdb85306"
      },
      "outputs": [],
      "source": [
        "class SumDimension(monai.transforms.Transform):\n",
        "    def __init__(self, dim=1):\n",
        "        self.dim = dim\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return inputs.sum(self.dim)\n",
        "\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImage(image_only=True), \n",
        "                                  monai.transforms.AddChannel(), \n",
        "                                  SumDimension()])\n",
        "img = trans(filenames[0][\"img\"])\n",
        "plt.imshow(img[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2659980e",
      "metadata": {
        "id": "2659980e"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f57b4d",
      "metadata": {
        "id": "c7f57b4d"
      },
      "outputs": [],
      "source": [
        "# Try to implement the transforms below into Compose()\n",
        "#   -  monai.transforms.Resize, size=(100, 100, 100)\n",
        "#   -  monai.transforms.RandFlip, prob=0.5\n",
        "\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImage(image_only=True), \n",
        "                                  monai.transforms.AddChannel(), \n",
        "                                  # Resize\n",
        "                                  # RandFlip\n",
        "                                  monai.transforms.RandGaussianNoise(prob=0.5, std=0.5),\n",
        "                                  monai.transforms.ToTensor(),])\n",
        "\n",
        "trans(filenames[0][\"img\"])\n",
        "print(type(img), img.shape)\n",
        "plt.imshow(img[0, 50], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20969a65",
      "metadata": {
        "id": "20969a65"
      },
      "outputs": [],
      "source": [
        "# Fix the Normalize transform (mean=0, std=1)\n",
        "class Normalize(monai.transforms.Transform):\n",
        "    def __init__(self):\n",
        "        None\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return inputs\n",
        "    \n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImage(image_only=True), \n",
        "                                  monai.transforms.AddChannel()])\n",
        "\n",
        "trans_norm = monai.transforms.Compose([monai.transforms.LoadImage(image_only=True), \n",
        "                                       monai.transforms.AddChannel(), \n",
        "                                       Normalize()])\n",
        "\n",
        "img = trans(filenames[0][\"img\"])\n",
        "img_norm = trans_norm(filenames[0][\"img\"])\n",
        "print('Original mean:', img.mean(), ', std:', img.std())\n",
        "print('Normalized mean:', img_norm.mean(), ', std:', img_norm.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3816b98",
      "metadata": {
        "id": "b3816b98"
      },
      "source": [
        "## Dictionary Transforms\n",
        "https://docs.monai.io/en/latest/highlights.html#transforms-support-both-dictionary-and-array-format-data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://docs.monai.io/en/stable/_images/multi_transform_chains.png)"
      ],
      "metadata": {
        "id": "_k64DU8Ofg8Z"
      },
      "id": "_k64DU8Ofg8Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc7d5a0",
      "metadata": {
        "id": "ecc7d5a0"
      },
      "outputs": [],
      "source": [
        "keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8f906676",
      "metadata": {
        "id": "8f906676"
      },
      "outputs": [],
      "source": [
        "# Dictionary version, the input data should be dictionary with keys\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys), # I/O\n",
        "                                  monai.transforms.AddChanneld(keys), # Pre-processing\n",
        "                                  monai.transforms.RandGaussianNoised(keys='img', prob=0.5, std=0.5), # Augmentation\n",
        "                                  monai.transforms.ToTensord(keys)]) # Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833ea102",
      "metadata": {
        "id": "833ea102"
      },
      "outputs": [],
      "source": [
        "filenames[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b298354",
      "metadata": {
        "id": "1b298354"
      },
      "outputs": [],
      "source": [
        "img_seg = trans(filenames[0])\n",
        "print(type(img_seg), img_seg['img'].shape, img_seg['img'].get_device())\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_seg['img'][0, 128], cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(img_seg['seg'][0, 128], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "305a9ecc",
      "metadata": {
        "id": "305a9ecc"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a81d15",
      "metadata": {
        "id": "e5a81d15"
      },
      "outputs": [],
      "source": [
        "# Fix the saveOriginalShaped transform\n",
        "\n",
        "class SaveOriginalShaped(monai.transforms.MapTransform):\n",
        "    def __init__(self, img_key, shape_key='ori_shape'):\n",
        "        self.img_key = img_key\n",
        "        self.shape_key = shape_key\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return inputs\n",
        "    \n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys), \n",
        "                                  monai.transforms.AddChanneld(keys), \n",
        "                                  SaveOriginalShaped('img', 'shape'),\n",
        "                                  monai.transforms.Resized(keys, spatial_size=(100, 100, 100),),\n",
        "                                  monai.transforms.ToTensord(keys)])\n",
        "\n",
        "img_seg = trans(filenames[0])\n",
        "img_seg['img'].shape, img_seg['shape']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e211b19b",
      "metadata": {
        "id": "e211b19b"
      },
      "source": [
        "## GPU Accelerated Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c66c76",
      "metadata": {
        "id": "80c66c76"
      },
      "source": [
        "- Without GPU Accelerated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89deae74",
      "metadata": {
        "id": "89deae74"
      },
      "outputs": [],
      "source": [
        "trans_list = [monai.transforms.LoadImage(image_only=True),\n",
        "              monai.transforms.EnsureType(),\n",
        "              monai.transforms.AddChannel(), \n",
        "              monai.transforms.ScaleIntensityRange(-1, 1),\n",
        "              monai.transforms.RandSpatialCrop(roi_size=(192, 192, 192)),\n",
        "              monai.transforms.Resize([100, 100, 100]),\n",
        "              monai.transforms.RandFlip(prob=1),\n",
        "              monai.transforms.RandGaussianNoise(prob=0.5, std=0.5),\n",
        "              monai.transforms.ToDevice(device='cuda:0'),]    \n",
        "trans = monai.transforms.Compose(trans_list)\n",
        "\n",
        "n = 20\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    img = trans(filenames[0][\"img\"])\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/n, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9160b3c7",
      "metadata": {
        "id": "9160b3c7"
      },
      "source": [
        "- With GPU Accelerated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3460491a",
      "metadata": {
        "id": "3460491a"
      },
      "outputs": [],
      "source": [
        "trans_list = [monai.transforms.LoadImage(image_only=True),\n",
        "              monai.transforms.EnsureType(),\n",
        "              monai.transforms.ToDevice(device='cuda:0'),\n",
        "              monai.transforms.AddChannel(), \n",
        "              monai.transforms.ScaleIntensityRange(-1, 1),\n",
        "              monai.transforms.RandSpatialCrop(roi_size=(192, 192, 192)),\n",
        "              monai.transforms.Resize([100, 100, 100]),\n",
        "              monai.transforms.RandFlip(prob=1),\n",
        "              monai.transforms.RandGaussianNoise(prob=0.5, std=0.5),]    \n",
        "trans = monai.transforms.Compose(trans_list)\n",
        "\n",
        "n = 20\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    img = trans(filenames[0][\"img\"])\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/n, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f69097f1",
      "metadata": {
        "id": "f69097f1"
      },
      "source": [
        "## Dataset\n",
        "https://docs.monai.io/en/latest/data.html\n",
        "- monai.data.Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52020d7",
      "metadata": {
        "id": "c52020d7"
      },
      "source": [
        "\"Users often need to train the model with many (potentially thousands of) epochs over the data to achieve the desired model quality. A native PyTorch implementation may repeatedly load data and run the same preprocessing steps for every epoch during training, which can be time-consuming and unnecessary, especially when the medical image volumes are large.\" <a href=\"https://docs.monai.io/en/latest/highlights.html#datasets-and-dataloader\">Source</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2031a435",
      "metadata": {
        "id": "2031a435"
      },
      "outputs": [],
      "source": [
        "items = [{\"data\": 1}, \n",
        "         {\"data\": 2}, \n",
        "         {\"data\": 3}, \n",
        "         {\"data\": 4}, \n",
        "         {\"data\": 5},\n",
        "         {\"data\": 6},\n",
        "         {\"data\": 7}]\n",
        "dataset = monai.data.Dataset(items, transform=None)\n",
        "\n",
        "print(f\"Length of dataset is {len(dataset)}\")\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1201a921",
      "metadata": {
        "id": "1201a921"
      },
      "outputs": [],
      "source": [
        "# Compatible with the PyTorch DataLoader\n",
        "for item in torch.utils.data.DataLoader(dataset, batch_size=2):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e630ce",
      "metadata": {
        "id": "a5e630ce"
      },
      "source": [
        "### Dataset Caching\n",
        "\n",
        "![image.png](https://docs.monai.io/en/stable/_images/cache_dataset.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc942011",
      "metadata": {
        "id": "dc942011"
      },
      "outputs": [],
      "source": [
        "class SlowSquare(monai.transforms.MapTransform):\n",
        "    def __init__(self, keys):\n",
        "        monai.transforms.MapTransform.__init__(self, keys)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        time.sleep(1.0) # delay 1 second here\n",
        "        output = {key: x[key] ** 2 for key in self.keys}\n",
        "        return output\n",
        "\n",
        "square_dataset = monai.data.Dataset(items, transform=SlowSquare(keys='data'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97f941cd",
      "metadata": {
        "id": "97f941cd"
      },
      "outputs": [],
      "source": [
        "%time for item in square_dataset: print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fe24e8d",
      "metadata": {
        "id": "6fe24e8d"
      },
      "source": [
        "### CacheDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83efbdb7",
      "metadata": {
        "id": "83efbdb7"
      },
      "outputs": [],
      "source": [
        "square_cached = monai.data.CacheDataset(items, transform=SlowSquare(keys='data'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7099eff5",
      "metadata": {
        "id": "7099eff5"
      },
      "outputs": [],
      "source": [
        "%time for item in square_cached: print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19a3346",
      "metadata": {
        "id": "a19a3346"
      },
      "source": [
        "### PersistentDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3389f765",
      "metadata": {
        "id": "3389f765"
      },
      "outputs": [],
      "source": [
        "!rm -r my_cache\n",
        "square_persist = monai.data.PersistentDataset(items, transform=SlowSquare(keys='data'), cache_dir=\"my_cache\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bf178db",
      "metadata": {
        "id": "9bf178db"
      },
      "outputs": [],
      "source": [
        "!ls my_cache/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696f757d",
      "metadata": {
        "id": "696f757d"
      },
      "outputs": [],
      "source": [
        "%time for item in square_persist: print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75443283",
      "metadata": {
        "id": "75443283"
      },
      "outputs": [],
      "source": [
        "!ls my_cache/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c82aa0f",
      "metadata": {
        "id": "4c82aa0f"
      },
      "outputs": [],
      "source": [
        "%time for item in square_persist: print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eb25228",
      "metadata": {
        "id": "3eb25228"
      },
      "source": [
        "### Exploration of CacheDataset and GPU Acceleration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe3bb407",
      "metadata": {
        "id": "fe3bb407"
      },
      "source": [
        "- Put the preprocessing transforms in the right position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24cbbc4a",
      "metadata": {
        "id": "24cbbc4a"
      },
      "outputs": [],
      "source": [
        "## Right\n",
        "class SlowSquare(monai.transforms.Transform):\n",
        "    def __init__(self):\n",
        "        None\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        time.sleep(1.0) # delay 1 second here\n",
        "        inputs = inputs ** 2\n",
        "        return inputs\n",
        "\n",
        "trans_list = [monai.transforms.LoadImage(image_only=True),\n",
        "              monai.transforms.EnsureType(),\n",
        "              monai.transforms.AddChannel(), \n",
        "              monai.transforms.ScaleIntensityRange(-1, 1),\n",
        "              SlowSquare(),\n",
        "              monai.transforms.RandSpatialCrop(roi_size=(192, 192, 192)),\n",
        "              monai.transforms.Resize([100, 100, 100]),\n",
        "              monai.transforms.RandFlip(prob=1),\n",
        "              monai.transforms.RandGaussianNoise(prob=0.5, std=0.5),\n",
        "              monai.transforms.ToDevice(device='cuda:0'),]    \n",
        "trans = monai.transforms.Compose(trans_list)\n",
        "\n",
        "data = [filenames[0][\"img\"] for i in range(5)]\n",
        "cached = monai.data.CacheDataset(data, transform=trans)\n",
        "\n",
        "n = 2\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    for i in cached:\n",
        "        i.shape\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/(n*len(cached)), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa96b1de",
      "metadata": {
        "id": "aa96b1de"
      },
      "outputs": [],
      "source": [
        "## Wrong\n",
        "trans_list = [monai.transforms.LoadImage(image_only=True),\n",
        "              monai.transforms.EnsureType(),\n",
        "              monai.transforms.AddChannel(), \n",
        "              monai.transforms.ScaleIntensityRange(-1, 1),\n",
        "              monai.transforms.RandSpatialCrop(roi_size=(192, 192, 192)),\n",
        "              SlowSquare(),\n",
        "              monai.transforms.Resize([100, 100, 100]),\n",
        "              monai.transforms.RandFlip(prob=1),\n",
        "              monai.transforms.RandGaussianNoise(prob=0.5, std=0.5),\n",
        "              monai.transforms.ToDevice(device='cuda:0'),]     \n",
        "trans = monai.transforms.Compose(trans_list)\n",
        "\n",
        "data = [filenames[0][\"img\"] for i in range(5)]\n",
        "cached = monai.data.CacheDataset(data, transform=trans)\n",
        "\n",
        "n = 2\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    for i in cached:\n",
        "        i.shape\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/n, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6c5148",
      "metadata": {
        "id": "7b6c5148"
      },
      "source": [
        "- GPU Acceleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fcacb83",
      "metadata": {
        "id": "6fcacb83"
      },
      "outputs": [],
      "source": [
        "trans_list = [monai.transforms.LoadImage(image_only=True),\n",
        "              monai.transforms.EnsureType(),\n",
        "              monai.transforms.ToDevice(device='cuda:0'),\n",
        "              monai.transforms.AddChannel(), \n",
        "              monai.transforms.ScaleIntensityRange(-1, 1),\n",
        "              SlowSquare(),\n",
        "              monai.transforms.RandSpatialCrop(roi_size=(192, 192, 192)),\n",
        "              monai.transforms.Resize([100, 100, 100]),\n",
        "              monai.transforms.RandFlip(prob=1),\n",
        "              monai.transforms.RandGaussianNoise(prob=0.5, std=0.5),]    \n",
        "trans = monai.transforms.Compose(trans_list)\n",
        "\n",
        "data = [filenames[0][\"img\"] for i in range(5)]\n",
        "cached = monai.data.CacheDataset(data, transform=trans)\n",
        "\n",
        "n = 20\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    for i in cached:\n",
        "        i.shape\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/(n*len(cached)), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e13a680",
      "metadata": {
        "id": "9e13a680"
      },
      "source": [
        "## Network\n",
        "https://docs.monai.io/en/latest/networks.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72032e1b",
      "metadata": {
        "id": "72032e1b"
      },
      "source": [
        "#### Built-in network\n",
        "- https://docs.monai.io/en/latest/networks.html#nets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52277372",
      "metadata": {
        "id": "52277372"
      },
      "outputs": [],
      "source": [
        "net = monai.networks.nets.UNet(\n",
        "    dimensions=3,  # 2 or 3 for a 2D or 3D network\n",
        "    in_channels=1,  # number of input channels\n",
        "    out_channels=1,  # number of output channels\n",
        "    channels=[8, 16],  # channel counts for layers\n",
        "    strides=[2]  # strides for mid layers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6014499",
      "metadata": {
        "id": "e6014499"
      },
      "outputs": [],
      "source": [
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf92089",
      "metadata": {
        "id": "5bf92089"
      },
      "outputs": [],
      "source": [
        "net(torch.ones(2, 1, 24, 24, 24)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d4c7b7",
      "metadata": {
        "id": "56d4c7b7"
      },
      "source": [
        "## Multi-GPU\n",
        "- Tutorials: https://github.com/Project-MONAI/tutorials/tree/master/acceleration/distributed_training\n",
        "- Horovod: https://github.com/horovod/horovod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52edf1e2",
      "metadata": {
        "id": "52edf1e2"
      },
      "source": [
        "## Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37731aa",
      "metadata": {
        "id": "b37731aa"
      },
      "source": [
        "1. Create a dummy dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70647a3b",
      "metadata": {
        "id": "70647a3b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dc0d0fca",
      "metadata": {
        "id": "dc0d0fca"
      },
      "source": [
        "2. Define a GPU accelerated dictionary transformation with `LoadImaged`, `AddChanneld`, `AddShiftIntensityd`, `RandSpatialCropd` and `ToTensord`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758fa386",
      "metadata": {
        "id": "758fa386"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f5bcf653",
      "metadata": {
        "id": "f5bcf653"
      },
      "source": [
        "3. Implement `CacheDataset`/`PersistentDataset` with PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb5207c",
      "metadata": {
        "id": "7fb5207c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8370f3ff",
      "metadata": {
        "id": "8370f3ff"
      },
      "source": [
        "4. Define a 3D UNet with 2 times pooling and 3 channels outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bceec1e8",
      "metadata": {
        "id": "bceec1e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "089d7df6",
      "metadata": {
        "id": "089d7df6"
      },
      "source": [
        "5. Feed the data generated by DataLoader to the UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "207d8d55",
      "metadata": {
        "id": "207d8d55"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}