{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference: MONAI Official GenerativeModel tutorials: https://github.com/Project-MONAI/GenerativeModels/blob/main/tutorials/generative/2d_ddpm/2d_ddpm_tutorial.ipynb"
      ],
      "metadata": {
        "id": "Phxm9ot4y3FJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Preparation"
      ],
      "metadata": {
        "id": "e2SZzxwRx71l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai[tqdm]"
      ],
      "metadata": {
        "id": "zYAQgYI6t0yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdwBDUdIspQL"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Project-MONAI/GenerativeModels.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GenerativeModels/\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "zWd8F-fmswuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup imports"
      ],
      "metadata": {
        "id": "l9qtvMJeyDEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from monai import transforms\n",
        "from monai.apps import MedNISTDataset\n",
        "from monai.config import print_config\n",
        "from monai.data import CacheDataset, DataLoader\n",
        "from monai.utils import first, set_determinism\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "\n",
        "from generative.inferers import DiffusionInferer\n",
        "from generative.networks import nets\n",
        "from generative.networks.schedulers import DDPMScheduler"
      ],
      "metadata": {
        "id": "buPWzfNktPcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download MedNIST Dataset"
      ],
      "metadata": {
        "id": "HJAPdxNGyPVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_determinism(42)\n",
        "root_dir = '../workspace'\n",
        "!mkdir $root_dir\n",
        "train_data = MedNISTDataset(root_dir=root_dir, section=\"training\", download=True, progress=False, seed=0)\n",
        "train_datalist = [{\"image\": item[\"image\"]} for item in train_data.data if item[\"class_name\"] == \"Hand\"]\n",
        "val_data = MedNISTDataset(root_dir=root_dir, section=\"validation\", download=True, progress=False, seed=0)\n",
        "val_datalist = [{\"image\": item[\"image\"]} for item in val_data.data if item[\"class_name\"] == \"Hand\"]"
      ],
      "metadata": {
        "id": "8FOG2qbntl_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforms and Dataloader Setup "
      ],
      "metadata": {
        "id": "MeoZD-HvyhM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.LoadImaged(keys=[\"image\"]),\n",
        "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
        "        transforms.Resized(keys=[\"image\"], spatial_size=[32, 32]),\n",
        "        transforms.RandAffined(\n",
        "            keys=[\"image\"],\n",
        "            rotate_range=[(-np.pi / 36, np.pi / 36), (-np.pi / 36, np.pi / 36)],\n",
        "            translate_range=[(-1, 1), (-1, 1)],\n",
        "            scale_range=[(-0.05, 0.05), (-0.05, 0.05)],\n",
        "            padding_mode=\"zeros\",\n",
        "            prob=0.5,\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "train_ds = CacheDataset(data=train_datalist, transform=train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
        "\n",
        "val_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.LoadImaged(keys=[\"image\"]),\n",
        "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
        "        transforms.Resized(keys=[\"image\"], spatial_size=[32, 32]),\n",
        "    ]\n",
        ")\n",
        "val_ds = CacheDataset(data=val_datalist, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)"
      ],
      "metadata": {
        "id": "eVbqfQMIveQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Data Preview"
      ],
      "metadata": {
        "id": "8wIuhHGmyyy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_data = first(train_loader)\n",
        "print(f\"batch shape: {check_data['image'].shape}\")\n",
        "image_visualisation = torch.cat(\n",
        "    [check_data[\"image\"][0, 0], check_data[\"image\"][1, 0], check_data[\"image\"][2, 0], check_data[\"image\"][3, 0]], dim=1\n",
        ")\n",
        "plt.figure(\"training images\", (12, 6))\n",
        "plt.imshow(image_visualisation, vmin=0, vmax=1, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3YQ7IADAv0t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model, DDPM Scheduler and Inferer"
      ],
      "metadata": {
        "id": "qUfF4UXB5qa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = nets.DiffusionModelUNet(\n",
        "    spatial_dims=2,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    num_channels=(32, 64, 64),\n",
        "    attention_levels=(False, True, True),\n",
        "    num_res_blocks=1,\n",
        "    num_head_channels=32,\n",
        "    norm_num_groups=8,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "num_train_timesteps=100\n",
        "scheduler = DDPMScheduler(num_train_timesteps=num_train_timesteps)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=2e-4)\n",
        "\n",
        "inferer = DiffusionInferer(scheduler)"
      ],
      "metadata": {
        "id": "UhVE8vDOysDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "GEP39VBI6sTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "val_interval = 5\n",
        "epoch_loss_list = []\n",
        "val_epoch_loss_list = []\n",
        "\n",
        "# setting for Auto Mixed Precision (AMP)\n",
        "scaler = GradScaler()\n",
        "total_start = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=70)\n",
        "    progress_bar.set_description(f\"Epoch {epoch+1}\")\n",
        "    ## Training ##\n",
        "    for step, batch in progress_bar:\n",
        "        images = batch[\"image\"].to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # setting for Auto Mixed Precision (AMP)\n",
        "        with autocast(enabled=True):\n",
        "            # Generate random noise\n",
        "            noise = torch.randn_like(images).to(device)\n",
        "\n",
        "            # Create timesteps\n",
        "            timesteps = torch.randint(\n",
        "                0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device\n",
        "            ).long()\n",
        "\n",
        "            # Get model prediction\n",
        "            noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)\n",
        "            loss = F.mse_loss(noise_pred.float(), noise.float())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        progress_bar.set_postfix({\"loss\": epoch_loss / (step + 1)})\n",
        "    epoch_loss_list.append(epoch_loss / (step + 1))\n",
        "    ## Validation ##\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        val_epoch_loss = 0\n",
        "        for step, batch in enumerate(val_loader):\n",
        "            images = batch[\"image\"].to(device)\n",
        "            with torch.no_grad():\n",
        "                with autocast(enabled=True):\n",
        "                    noise = torch.randn_like(images).to(device)\n",
        "                    timesteps = torch.randint(\n",
        "                        0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device\n",
        "                    ).long()\n",
        "\n",
        "                    noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)\n",
        "                    \n",
        "                    val_loss = F.mse_loss(noise_pred.float(), noise.float())\n",
        "\n",
        "            val_epoch_loss += val_loss.item()\n",
        "            progress_bar.set_postfix({\"val_loss\": val_epoch_loss / (step + 1)})\n",
        "        val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
        "\n",
        "        # Sampling image during training\n",
        "        noise = torch.randn((1, 1, 64, 64))\n",
        "        noise = noise.to(device)\n",
        "        scheduler.set_timesteps(num_inference_steps=num_train_timesteps)\n",
        "        with autocast(enabled=True):\n",
        "            image = inferer.sample(input_noise=noise, diffusion_model=model, scheduler=scheduler)\n",
        "\n",
        "        plt.figure(figsize=(2, 2))\n",
        "        plt.imshow(image[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
        "        plt.tight_layout()\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "total_time = time.time() - total_start\n",
        "print(f\"train completed, total time: {total_time}.\")"
      ],
      "metadata": {
        "id": "YE0sRwUq5f5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DDPM Visualization"
      ],
      "metadata": {
        "id": "_I5CUZ5x_NHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ddpm_vis():\n",
        "    model.eval()\n",
        "    noise = torch.randn((1, 1, 64, 64))\n",
        "    noise = noise.to(device)\n",
        "    scheduler.set_timesteps(num_inference_steps=num_train_timesteps)\n",
        "    with autocast(enabled=True):\n",
        "        image, intermediates = inferer.sample(\n",
        "            input_noise=noise, diffusion_model=model, scheduler=scheduler, save_intermediates=True, intermediate_steps=num_train_timesteps//10\n",
        "        )\n",
        "\n",
        "    chain = torch.cat(intermediates, dim=-1)\n",
        "\n",
        "    plt.style.use(\"default\")\n",
        "    plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
        "    plt.tight_layout()\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "ddpm_vis()"
      ],
      "metadata": {
        "id": "AeQxSsNK_QKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_vis()"
      ],
      "metadata": {
        "id": "McRxXN5EDdan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCClIuyYDeWq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
