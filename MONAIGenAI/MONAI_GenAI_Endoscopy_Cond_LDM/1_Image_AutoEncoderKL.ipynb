{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The First Step: Image AutoEncoderKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2SZzxwRx71l"
   },
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYAQgYI6t0yM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install monai[tqdm] lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdwBDUdIspQL"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Project-MONAI/GenerativeModels.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWd8F-fmswuf",
    "outputId": "8da56c97-faa6-4a74-e221-a3caaf381c2c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd GenerativeModels/\n",
    "!python setup.py install\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r GenerativeModels/\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9qtvMJeyDEd"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buPWzfNktPcs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.utils import first, set_determinism\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.inferers import LatentDiffusionInferer\n",
    "from generative.losses import PatchAdversarialLoss, PerceptualLoss\n",
    "from generative.networks import nets\n",
    "from generative.networks.schedulers import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generative\n",
    "generative.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJAPdxNGyPVm"
   },
   "source": [
    "## Prepare Kvasir-SEG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FOG2qbntl_D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_determinism(42)\n",
    "\n",
    "!wget https://datasets.simula.no/downloads/kvasir-seg.zip\n",
    "!unzip kvasir-seg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Bd5Fc3URcgb",
    "outputId": "dc93ca60-f8a5-44c2-98a8-edc6e7812743"
   },
   "outputs": [],
   "source": [
    "path_img = './Kvasir-SEG/images/'\n",
    "path_msk = './Kvasir-SEG/masks/'\n",
    "fnames_img = [f for f in os.listdir(path_img) if '.jpg' in f]\n",
    "datalist = []\n",
    "for fname in fnames_img:\n",
    "    data = {'image': path_img+fname, 'seg': path_msk+fname}\n",
    "    datalist.append(data)\n",
    "\n",
    "# Shuffle\n",
    "# np.random.shuffle(datalist)\n",
    "# Split the datalist to train and validation\n",
    "train_datalist = datalist[:950]\n",
    "val_datalist = datalist[950:]\n",
    "datalist[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeoZD-HvyhM_"
   },
   "source": [
    "### Transforms and Dataloader Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVbqfQMIveQS",
    "outputId": "2321a0c9-6d07-425c-b2bf-a924a7ceb7ce"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "target_key = 'image'\n",
    "shape = [128, 128]\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=target_key),\n",
    "        transforms.EnsureChannelFirstd(keys=target_key),\n",
    "        transforms.Resized(keys=target_key, spatial_size=shape),\n",
    "        transforms.ScaleIntensityRanged(keys=target_key, a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        transforms.RandAffined(\n",
    "            keys=target_key,\n",
    "            rotate_range=[(-np.pi / 36, np.pi / 36), (-np.pi / 36, np.pi / 36)],\n",
    "            scale_range=[(-0.05, 0.05), (-0.05, 0.05)],\n",
    "            padding_mode=\"zeros\",\n",
    "            prob=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "train_ds = CacheDataset(data=train_datalist, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=target_key),\n",
    "        transforms.EnsureChannelFirstd(keys=target_key),\n",
    "        transforms.Resized(keys=target_key, spatial_size=shape),\n",
    "        transforms.ScaleIntensityRanged(keys=target_key, a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ]\n",
    ")\n",
    "val_ds = CacheDataset(data=val_datalist, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wIuhHGmyyy3"
   },
   "source": [
    "### Training Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "3YQ7IADAv0t3",
    "outputId": "6dd97cbd-47ea-4e1e-c5fd-801722457df7"
   },
   "outputs": [],
   "source": [
    "check_data = first(train_loader)\n",
    "print(f\"batch shape: {check_data[target_key].shape}\")\n",
    "image_visualisation = check_data[target_key][0].numpy()\n",
    "plt.figure(\"training images\", (3, 3))\n",
    "plt.imshow(image_visualisation.transpose([2, 1, 0]), vmin=0, vmax=1)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUfF4UXB5qa9"
   },
   "source": [
    "### Define models, optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhVE8vDOysDj"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "autoencoder = nets.AutoencoderKL(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    num_channels=(32, 64, 64),\n",
    "    latent_channels=3,\n",
    "    num_res_blocks=1,\n",
    "    norm_num_groups=16,\n",
    "    attention_levels=(False, False, True),\n",
    ").to(device)\n",
    "\n",
    "discriminator = nets.PatchDiscriminator(spatial_dims=2, num_layers_d=3, num_channels=32, in_channels=3, out_channels=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss = torch.nn.L1Loss()\n",
    "adv_loss = PatchAdversarialLoss(criterion=\"least_squares\")\n",
    "loss_perceptual = PerceptualLoss(spatial_dims=2, network_type=\"squeeze\", is_fake_3d=True, fake_3d_ratio=0.2).to(device)\n",
    "\n",
    "def KL_loss(z_mu, z_sigma):\n",
    "    kl_loss = 0.5 * torch.sum(z_mu.pow(2) + z_sigma.pow(2) - torch.log(z_sigma.pow(2)) - 1, dim=[1, 2, 3])\n",
    "    return torch.sum(kl_loss) / kl_loss.shape[0]\n",
    "\n",
    "adv_weight = 0.01\n",
    "perceptual_weight = 0.001\n",
    "kl_weight = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = torch.optim.Adam(params=autoencoder.parameters(), lr=1e-4)\n",
    "optimizer_d = torch.optim.Adam(params=discriminator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEP39VBI6sTv"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "YE0sRwUq5f5g",
    "outputId": "0d26912d-7d9e-4f1d-f3e8-b873fd4e9540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "autoencoder_warm_up_n_epochs = 5\n",
    "val_interval = 10\n",
    "epoch_recon_loss_list = []\n",
    "epoch_gen_loss_list = []\n",
    "epoch_disc_loss_list = []\n",
    "val_recon_epoch_loss_list = []\n",
    "intermediary_images = []\n",
    "n_example_images = 4\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    autoencoder.train()\n",
    "    discriminator.train()\n",
    "    epoch_loss = 0\n",
    "    gen_epoch_loss = 0\n",
    "    disc_epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=110)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in progress_bar:\n",
    "        images = batch[\"image\"].to(device)  # choose only one of Brats channels\n",
    "\n",
    "        # Generator part\n",
    "        optimizer_g.zero_grad(set_to_none=True)\n",
    "        reconstruction, z_mu, z_sigma = autoencoder(images)\n",
    "        kl_loss = KL_loss(z_mu, z_sigma)\n",
    "\n",
    "        recons_loss = l1_loss(reconstruction.float(), images.float())\n",
    "        p_loss = loss_perceptual(reconstruction.float(), images.float())\n",
    "        loss_g = recons_loss + kl_weight * kl_loss + perceptual_weight * p_loss\n",
    "\n",
    "        if epoch > autoencoder_warm_up_n_epochs:\n",
    "            logits_fake = discriminator(reconstruction.contiguous().float())[-1]\n",
    "            generator_loss = adv_loss(logits_fake, target_is_real=True, for_discriminator=False)\n",
    "            loss_g += adv_weight * generator_loss\n",
    "\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        if epoch > autoencoder_warm_up_n_epochs:\n",
    "            # Discriminator part\n",
    "            optimizer_d.zero_grad(set_to_none=True)\n",
    "            logits_fake = discriminator(reconstruction.contiguous().detach())[-1]\n",
    "            loss_d_fake = adv_loss(logits_fake, target_is_real=False, for_discriminator=True)\n",
    "            logits_real = discriminator(images.contiguous().detach())[-1]\n",
    "            loss_d_real = adv_loss(logits_real, target_is_real=True, for_discriminator=True)\n",
    "            discriminator_loss = (loss_d_fake + loss_d_real) * 0.5\n",
    "\n",
    "            loss_d = adv_weight * discriminator_loss\n",
    "\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "        epoch_loss += recons_loss.item()\n",
    "        if epoch > autoencoder_warm_up_n_epochs:\n",
    "            gen_epoch_loss += generator_loss.item()\n",
    "            disc_epoch_loss += discriminator_loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"recons_loss\": epoch_loss / (step + 1),\n",
    "                \"gen_loss\": gen_epoch_loss / (step + 1),\n",
    "                \"disc_loss\": disc_epoch_loss / (step + 1),\n",
    "            }\n",
    "        )\n",
    "    epoch_recon_loss_list.append(epoch_loss / (step + 1))\n",
    "    epoch_gen_loss_list.append(gen_epoch_loss / (step + 1))\n",
    "    epoch_disc_loss_list.append(disc_epoch_loss / (step + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.state_dict(), os.path.join('models', 'AE_img.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.title(\"Learning Curves\", fontsize=20)\n",
    "plt.plot(epoch_recon_loss_list)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Adversarial Training Curves\", fontsize=20)\n",
    "plt.plot(epoch_gen_loss_list, color=\"C0\", linewidth=2.0, label=\"Generator\")\n",
    "plt.plot(epoch_disc_loss_list, color=\"C1\", linewidth=2.0, label=\"Discriminator\")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot axial, coronal and sagittal slices of a training sample\n",
    "idx = 0\n",
    "\n",
    "plt.figure(figsize=(4, 8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(images[idx].detach().cpu().numpy().transpose([2, 1, 0]), vmin=0, vmax=1)\n",
    "plt.title('Origin')\n",
    "plt.subplot(122)\n",
    "plt.imshow(reconstruction[idx].detach().cpu().numpy().transpose([2, 1, 0]), vmin=0, vmax=1)\n",
    "plt.title('Reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
