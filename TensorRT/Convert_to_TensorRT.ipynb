{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60899d8",
   "metadata": {},
   "source": [
    "## TensorRT Tool\n",
    "- Built-in package in the PyTorch container\n",
    "- Simple one line command!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfed8d",
   "metadata": {},
   "source": [
    "#### Convert to TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788cf461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!trtexec --onnx=../MONAICore/model.onnx --saveEngine=model.engine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92229f91",
   "metadata": {},
   "source": [
    "#### Convert to TensorRT with FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058151a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!trtexec --onnx=../MONAICore/model.onnx --saveEngine=model_fp16.engine --fp16 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6f91f",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import time\n",
    "import monai\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_infers = 100\n",
    "batch_size = 32\n",
    "input_image = np.random.normal(size=[batch_size, 3, 256, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3229d",
   "metadata": {},
   "source": [
    "- PyTroch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ad781",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = monai.networks.nets.SegResNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    dropout_prob=.5\n",
    ").to(device)\n",
    "state_dict = torch.load('../MONAICore/checkpoints/best.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "img_tensor = torch.Tensor(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adf07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "with torch.no_grad():\n",
    "    for i in range(n_infers):\n",
    "        model(img_tensor.to(device))\n",
    "t2 = time.time()\n",
    "throughputs_torch = batch_size*n_infers/(t2-t1)\n",
    "print('Throughputs:', round(throughputs_torch, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26fe13",
   "metadata": {},
   "source": [
    "- TensorRT FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22407570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRT_setup(engine_path='./model.engine'):\n",
    "    TRT_LOGGER = trt.Logger()\n",
    "    trt.init_libnvinfer_plugins(None,'')\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "    context = engine.create_execution_context()\n",
    "    bindings = []\n",
    "    for binding in engine:\n",
    "        binding_idx = engine.get_binding_index(binding)\n",
    "        size = trt.volume(context.get_binding_shape(binding_idx))\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        if engine.binding_is_input(binding):\n",
    "            input_buffer = np.ascontiguousarray(input_image)\n",
    "            input_memory = cuda.mem_alloc(input_image.nbytes)\n",
    "            bindings.append(int(input_memory))\n",
    "        else:\n",
    "            output_buffer = cuda.pagelocked_empty(size, dtype)\n",
    "            output_memory = cuda.mem_alloc(output_buffer.nbytes)\n",
    "            bindings.append(int(output_memory))\n",
    "    return context, input_buffer, input_memory, output_buffer, output_memory, bindings\n",
    "    \n",
    "def infer(context, input_buffer, input_memory, output_buffer, output_memory, bindings):\n",
    "    stream = cuda.Stream()\n",
    "    # Transfer input data to the GPU.\n",
    "    cuda.memcpy_htod_async(input_memory, input_buffer, stream)\n",
    "    # Run inference\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer prediction output from the GPU.\n",
    "    cuda.memcpy_dtoh_async(output_buffer, output_memory, stream)\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "context, input_buffer, input_memory, output_buffer, output_memory, bindings = TRT_setup('./model.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "for i in range(n_infers):\n",
    "    pred = infer(context, input_buffer, input_memory, output_buffer, output_memory, bindings)\n",
    "t2 = time.time()\n",
    "throughputs_trtfp32 = batch_size*n_infers/(t2-t1)\n",
    "print('Throughputs:', round(throughputs_trtfp32, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c305c4a",
   "metadata": {},
   "source": [
    "- TensorRT FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context, input_buffer, input_memory, output_buffer, output_memory, bindings = TRT_setup('./model_fp16.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68100454",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "for i in range(n_infers):\n",
    "    pred = infer(context, input_buffer, input_memory, output_buffer, output_memory, bindings)\n",
    "t2 = time.time()\n",
    "throughputs_trtfp16 = batch_size*n_infers/(t2-t1)\n",
    "print('Throughputs:', round(throughputs_trtfp16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea307da",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Try `trtexec` yourself, explore the tool's configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476e7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!trtexec -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09095d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
